# U-net
U-Net, a convolutional network architecture for biomedical image segmentation, and a training strategy that relies heavily on data augmentation. The U-Net architecture is novel in that it combines a contracting path to capture context and a symmetric expanding path that enables precise localization. The network can be trained end-to-end with very few images, and it outperforms previous methods in segmenting neuronal structures in electron microscopic stacks. 

Key Ideas:

- **U-shaped architecture:** The network's architecture is characterized by a contracting path, similar to a typical convolutional network, and an expansive path, where pooling operations are replaced by upsampling, resulting in a U-shape. This allows the network to increase the resolution of the output. High-resolution features from the contracting path are combined with the upsampled output to improve localization. The expansive path is symmetric to the contracting path, with a large number of feature channels that propagate context information to higher resolution layers.
- **Data Augmentation:** The paper emphasizes the importance of data augmentation, particularly elastic deformations, for training the network with limited data. This allows the network to learn invariance to such deformations. The authors use random displacement vectors on a coarse grid to generate smooth deformations.
- **Weighted loss:** The paper introduces the use of a weighted loss to address the challenge of separating touching objects of the same class. Separating background labels between touching cells are given a large weight in the loss function to force the network to learn the border pixels. The weight map is computed to balance class frequencies and enhance the separation borders.
- **No fully connected layers:** The network does not use any fully connected layers, which allows it to process arbitrarily large images and only uses the valid part of each convolution.

The U-Net architecture consists of a contracting path (left side) and an expansive path (right side). The contracting path has repeated applications of two 3x3 convolutions, each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation for downsampling. At each downsampling step, the number of feature channels is doubled. Every step in the expansive path includes an upsampling of the feature map followed by a 2x2 convolution, halving the number of feature channels, concatenation with the cropped feature map from the contracting path, and two 3x3 convolutions each followed by a ReLU. Cropping is necessary due to the loss of border pixels in convolutions. At the final layer, a 1x1 convolution maps each 64-component feature vector to the desired number of classes. The network has a total of 23 convolutional layers.

The U-Net architecture requires very few annotated images due to data augmentation and has a training time of only 10 hours on an NVidia Titan GPU. The U-Net's performance was demonstrated on three different segmentation tasks. It achieved state-of-the-art results in segmenting neuronal structures in electron microscopy (EM) stacks, outperforming a sliding-window convolutional network. The network also achieved superior results in cell segmentation in light microscopy images from the ISBI cell tracking challenge 2015, surpassing the second best algorithms by a large margin.
