# Session of Machine Learning Division of CyberLabs:

Conducted on 2nd March 2025  
## Agenda of Meet  
Discussion on BEiT (BERT Pre-training of Image Transformers) and ViT (Vision Transformer)

## Summary  
We explored the architectures and principles behind BEiT (BERT Pre-training of Image Transformers) and Vision Transformer (ViT). The session covered how BEiT adapts BERT-style masked image modeling for pretraining vision transformers using image patches and discrete tokens. We also discussed how ViT applies the transformer architecture to images by treating them as sequences of patches. Doubts were addressed related to how BEiT differs from ViT, the concept of patch tokenization, positional embeddings, and the effectiveness of masked image modeling in comparison to supervised pretraining.

## Attendees  
Pre Final Years – Manav Jain, Karaka Prasanth Naidu

Second Years – Green Kedia, Abhinav Jha, Daksh Mor, Dilshad Raza, Mohd. Ashaz Khan, Priyam Pritam Panda, Mukil M, Harshvardhan Saini, Jeevesh Kumar

## Absentees
Second Years - Geeth Chand Chinni

## Report by  
Dilshad Raza
