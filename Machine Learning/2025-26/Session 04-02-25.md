# Session of Machine Learning Division of CyberLabs
Conducted on: 4th February 2025

## Agenda
Discussion of Machine Learning Specialisation Course 2 and 3

## Summary
1. Activation Characteristics:
   - Analysis of periodicity, vertical line test, and monotonicity
   - Special activation functions including sinx
   - Circuit theory for neural networks

2. Principal Component Analysis:
   - Need for centering data
   - Importance of maintaining equal variance

3. K-means Clustering:
   - In-depth discussion on random initialization
   - Analysis of theoretical convergence epochs

4. Mini batch vs Stochastic Gradient Descent:
   - Sampling without replacement preferred over sampling with replacement in most ML models
   - Exception noted for Random Forest
   - Advantages include faster convergence without overfitting

5. Softmax Derivative:
   - Concept revision completed

6. Doubt Sheet:
   - Initiated doubt discussion
   - Some questions resolved

## Agenda for the next session
- KNN Vectorized Implementation (using broadcasting)
- Deep Learning Course 1
- Resolving Doubt Sheet

## Report Compiled by
Sreenandan Shashidharan

## Attendees
Second Year Attendees: Green Kedia, Dilshad Raza, Mohammad Ashaz Khan, Mukil M, Harshvardhan Saini, Abhinav Jha, Daksh Mor, Priyam Pritam Panda, Chinni Geet Chand

First Year Attendees: Anab, Arnav, Ritesh, Rajat, Arjav, Abhishek, Ayushman, Sreenandan, Anukul

## Absentees
First Year: None
